<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="iroha"><meta name="copyright" content="iroha"><meta name="generator" content="Hexo 6.3.0"><meta name="theme" content="hexo-theme-yun"><title>transformer结构与代码 | iroha</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...undefined?.options,
  });
});</script><link rel="icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"example.com","root":"/","title":"不想摆烂","version":"1.10.9","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","say":{"api":"https://el-bot-api.vercel.app/api/words/young"},"fireworks":{"colors":null},"vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><meta name="description" content="代码总览 class Transformer(nn.Module):      def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,                  ffn_hidden, n_layers, drop_pro">
<meta property="og:type" content="article">
<meta property="og:title" content="transformer结构与代码">
<meta property="og:url" content="http://example.com/post/transformer.html">
<meta property="og:site_name" content="iroha">
<meta property="og:description" content="代码总览 class Transformer(nn.Module):      def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,                  ffn_hidden, n_layers, drop_pro">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/image-20240316142251107.png">
<meta property="og:image" content="http://example.com/images/image-20240316154402911.png">
<meta property="og:image" content="http://example.com/images/image-20240315232326148.png">
<meta property="article:published_time" content="2024-04-01T08:08:00.000Z">
<meta property="article:modified_time" content="2024-07-22T09:15:38.348Z">
<meta property="article:author" content="iroha">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/image-20240316142251107.png"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><script defer src="https://fastly.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js" type="module"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="iroha"><img width="96" loading="lazy" src="/yun.png" alt="iroha"><span class="site-author-status" title="永远相信美好的事情即将发生">😊</span></a><div class="site-author-name"><a href="/about/">iroha</a></div><span class="site-name">iroha</span><sub class="site-subtitle"></sub><div class="site-description"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:archive-line"></span></span><span class="site-state-item-count">14</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:folder-2-line"></span></span><span class="site-state-item-count">4</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="site-state-item-count">2</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:settings-line"></span></span></a></nav><hr style="margin-bottom:0.5rem"><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="友链" style="color:dodgerblue"><span class="icon iconify" data-icon="ri:genderless-line"></span></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><span class="icon iconify" data-icon="ri:contrast-2-line"></span></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%80%BB%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">代码总览</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#embedding"><span class="toc-number">2.</span> <span class="toc-text">Embedding</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#encoder"><span class="toc-number">3.</span> <span class="toc-text">Encoder</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#multiheadattention"><span class="toc-number">3.1.</span> <span class="toc-text">MultiHeadAttention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scaled-dot-product-attention"><span class="toc-number">3.1.1.</span> <span class="toc-text">Scaled Dot-Product Attention</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#add-norm"><span class="toc-number">3.2.</span> <span class="toc-text">ADD &amp; NORM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#position-wise-feed-forward-networks"><span class="toc-number">3.3.</span> <span class="toc-text">Position-wise Feed-Forward
Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#add-norm-1"><span class="toc-number">3.4.</span> <span class="toc-text">ADD &amp; Norm</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#decoder"><span class="toc-number">4.</span> <span class="toc-text">Decoder</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#maskedmultiheadattention"><span class="toc-number">4.1.</span> <span class="toc-text">MaskedMultiHeadAttention</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#multiheadattention-1"><span class="toc-number">4.2.</span> <span class="toc-text">MultiHeadAttention</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#position-wise-feed-forward-networks-1"><span class="toc-number">4.3.</span> <span class="toc-text">Position-wise
Feed-Forward Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear"><span class="toc-number">4.4.</span> <span class="toc-text">Linear</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#softmax"><span class="toc-number">4.5.</span> <span class="toc-text">softmax</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="http://example.com/post/transformer.html"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="iroha"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="iroha"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">transformer结构与代码</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="创建时间：2024-04-01 16:08:00" itemprop="dateCreated datePublished" datetime="2024-04-01T16:08:00+08:00">2024-04-01</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-2-line"></span></span> <time title="修改时间：2024-07-22 17:15:38" itemprop="dateModified" datetime="2024-07-22T17:15:38+08:00">2024-07-22</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><span class="icon iconify" data-icon="ri:folder-line"></span></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/NLP/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">NLP</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="tag-name">大模型</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><h1 id="代码总览">代码总览</h1>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">class Transformer(nn.Module):

    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,
                 ffn_hidden, n_layers, drop_prob, device):
        super().__init__()
        self.src_pad_idx &#x3D; src_pad_idx
        self.trg_pad_idx &#x3D; trg_pad_idx
        self.trg_sos_idx &#x3D; trg_sos_idx
        self.device &#x3D; device
        self.encoder &#x3D; Encoder(d_model&#x3D;d_model,
                               n_head&#x3D;n_head,
                               max_len&#x3D;max_len,
                               ffn_hidden&#x3D;ffn_hidden,
                               enc_voc_size&#x3D;enc_voc_size,
                               drop_prob&#x3D;drop_prob,
                               n_layers&#x3D;n_layers,
                               device&#x3D;device)

        self.decoder &#x3D; Decoder(d_model&#x3D;d_model,
                               n_head&#x3D;n_head,
                               max_len&#x3D;max_len,
                               ffn_hidden&#x3D;ffn_hidden,
                               dec_voc_size&#x3D;dec_voc_size,
                               drop_prob&#x3D;drop_prob,
                               n_layers&#x3D;n_layers,
                               device&#x3D;device)

    def forward(self, src, trg):
        src_mask &#x3D; self.make_src_mask(src)
        trg_mask &#x3D; self.make_trg_mask(trg)
        enc_src &#x3D; self.encoder(src, src_mask)
        output &#x3D; self.decoder(trg, enc_src, trg_mask, src_mask)
        return output

    def make_src_mask(self, src):
        src_mask &#x3D; (src !&#x3D; self.src_pad_idx).unsqueeze(1).unsqueeze(2)
        return src_mask

    def make_trg_mask(self, trg):
        trg_pad_mask &#x3D; (trg !&#x3D; self.trg_pad_idx).unsqueeze(1).unsqueeze(3)
        trg_len &#x3D; trg.shape[1]
        trg_sub_mask &#x3D; torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)
        trg_mask &#x3D; trg_pad_mask &amp; trg_sub_mask
        return trg_mask</code></pre>
<figure>
<img src="../images/image-20240316142251107.png"
alt="image-20240316142251107" />
<figcaption aria-hidden="true">image-20240316142251107</figcaption>
</figure>
<h1 id="embedding">Embedding</h1>
<p>Embedding分为Token Embedding和Position
Encoding，二者结果直接相加，之后先layernorm(原始transformer里没，bert有)再dropout。</p>
<p>token Embedding的实现为</p>
<pre class="line-numbers language-none"><code class="language-none">tok_emb &#x3D; nn.Embedding(vocab_size,d_model,pad_id)
</code></pre>
<p>Pos emb稍微比较麻烦。Transformer用的是绝对位置编码，与token
emb直接相加。其中i是 <span class="math display">\[
\text{PE}_{(pos, 2i)} =
\sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right) \\
\text{PE}_{(pos, 2i+1)} =
\cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right)
\]</span></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">class PositionEncoding(nn.Module):
	def __init__(self,d_model,max_len,device):
        super().__init__()
        self.encoding &#x3D; torch.zeros(max_len,d_model,device&#x3D;device)
        self.encoding.requires_grad &#x3D; False
        pos &#x3D; torch.arange(d_model,device&#x3D;device)
        pos &#x3D; pos.float().unsqueeze(dim&#x3D;1)
        _2i &#x3D; torch.arange(0,max_len,step&#x3D;2,device&#x3D;device).float() 
        self.encoding[:,0::2] &#x3D; torch.sin(pos&#x2F;10000**(_2i&#x2F;d_model))
        self.encoding[:,1::2] &#x3D; torch.cos(pos&#x2F;10000**(_2i&#x2F;d_model))</code></pre>
<h1 id="encoder">Encoder</h1>
<p>整个encoder层有两次残差连接，并且需要把被padding的部分带掩码上。被mask的地方可以设置为一个非常非常小的负数，让他对softmax贡献降低。</p>
<figure>
<img src="../images/image-20240316154402911.png"
alt="image-20240316154402911" />
<figcaption aria-hidden="true">image-20240316154402911</figcaption>
</figure>
<h2 id="multiheadattention">MultiHeadAttention</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">class MultiHeadAttention(nn.Module):

    def __init__(self, d_model, n_head):
        super(MultiHeadAttention, self).__init__()
        self.n_head &#x3D; n_head
        self.attention &#x3D; ScaleDotProductAttention()
        self.w_q &#x3D; nn.Linear(d_model, d_model)
        self.w_k &#x3D; nn.Linear(d_model, d_model)
        self.w_v &#x3D; nn.Linear(d_model, d_model)
        self.w_concat &#x3D; nn.Linear(d_model, d_model) #  Wo

    def forward(self, q, k, v, mask&#x3D;None):
        # 1. dot product with weight matrices
        q, k, v &#x3D; self.w_q(q), self.w_k(k), self.w_v(v)

        # 2. split tensor by number of heads
        q, k, v &#x3D; self.split(q), self.split(k), self.split(v)

        # 3. do scale dot product to compute similarity
        out, attention &#x3D; self.attention(q, k, v, mask&#x3D;mask)

        # 4. concat and pass to linear layer
        out &#x3D; self.concat(out)
        out &#x3D; self.w_concat(out)

        # 5. visualize attention map
        # TODO : we should implement visualization

        return out</code></pre>
<figure>
<img src="../images/image-20240315232326148.png"
alt="image-20240315232326148" />
<figcaption aria-hidden="true">image-20240315232326148</figcaption>
</figure>
<p>用点积注意力可以高度并行，对于较大的dk值，加法注意力在性能上优于无缩放的点积注意力，除以根号dk的原因是怕softmax输出的梯度太小。</p>
<p>https://blog.csdn.net/qq_37430422/article/details/105042303</p>
<p>$ Attention(Q,K,V) = softmax()V$</p>
<h3 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h3>
<p>Q,K,V会经过一个线性层(d,d)，然后拆分送给多个Attention，这里请注意，是把序列给拆了！不是把tensor铺开来然后划分，所以需要坐transpose</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor &#x3D; tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)</code></pre>
<p>之后将q,k,v传入点积attention</p>
<pre class="line-numbers language-none"><code class="language-none">class ScaleDotProductAttention(nn.Module):
    &quot;&quot;&quot;
    compute scale dot product attention

    Query : given sentence that we focused on (decoder)
    Key : every sentence to check relationship with Qeury(encoder)
    Value : every sentence same with Key (encoder)
    &quot;&quot;&quot;

    def __init__(self):
        super(ScaleDotProductAttention, self).__init__()
        self.softmax &#x3D; nn.Softmax(dim&#x3D;-1)

    def forward(self, q, k, v, mask&#x3D;None, e&#x3D;1e-12):
        # input is 4 dimension tensor
        # [batch_size, head, length, d_tensor]
        batch_size, head, length, d_tensor &#x3D; k.size()

        # 1. dot product Query with Key^T to compute similarity
        k_t &#x3D; k.transpose(2, 3)  # transpose
        score &#x3D; (q @ k_t) &#x2F; math.sqrt(d_tensor)  # scaled dot product

        # 2. apply masking (opt)
        if mask is not None:
            score &#x3D; score.masked_fill(mask &#x3D;&#x3D; 0, -10000)

        # 3. pass them softmax to make [0, 1] range
        score &#x3D; self.softmax(score)

        # 4. multiply with Value
        v &#x3D; score @ v

        return v, score
</code></pre>
<p>每一个head并行计算完attention后，重新concat起来，Wo如果在head能被dmodel整除的情况下，拼起来就是一个512×512的矩阵。</p>
<h2 id="add-norm">ADD &amp; NORM</h2>
<pre class="line-numbers language-none"><code class="language-none">x &#x3D; self.attention(q&#x3D;x, k&#x3D;x, v&#x3D;x, mask&#x3D;src_mask)

# 2. add and norm
x &#x3D; self.dropout1(x)
x &#x3D; self.norm1(x + _x)</code></pre>
<h2 id="position-wise-feed-forward-networks">Position-wise Feed-Forward
Networks</h2>
<p>这个做法可以增加模型的表示能力，并且增加了模型学习的灵活性。通过将维度映射到更高的维度，模型能够学习更复杂的特征，然后通过第二个线性层将其映射回原始的维度，以保留原始输入的信息。这种设计可以帮助模型更好地学习输入序列之间的复杂关系，并且提高模型的性能。原始的隐藏层是2048</p>
<pre class="line-numbers language-none"><code class="language-none">class PositionwiseFeedForward(nn.Module):

    def __init__(self, d_model, hidden, drop_prob&#x3D;0.1):
        super(PositionwiseFeedForward, self).__init__()
        self.linear1 &#x3D; nn.Linear(d_model, hidden)
        self.linear2 &#x3D; nn.Linear(hidden, d_model)
        self.relu &#x3D; nn.ReLU()
        self.dropout &#x3D; nn.Dropout(p&#x3D;drop_prob)

    def forward(self, x):
        x &#x3D; self.linear1(x)
        x &#x3D; self.relu(x)
        x &#x3D; self.dropout(x)
        x &#x3D; self.linear2(x)
        return x</code></pre>
<h2 id="add-norm-1">ADD &amp; Norm</h2>
<pre class="line-numbers language-none"><code class="language-none"># 3. positionwise feed forward network
_x &#x3D; x
x &#x3D; self.ffn(x)
      
# 4. add and norm
x &#x3D; self.dropout2(x)
x &#x3D; self.norm2(x + _x)
return x</code></pre>
<h1 id="decoder">Decoder</h1>
<p>在训练时，Decoder的emb输入不是上一步生成的，而是目标序列。Decoder有三次残差</p>
<pre class="line-numbers language-none"><code class="language-none">class Decoder(nn.Module):
    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):
        super().__init__()
        self.emb &#x3D; TransformerEmbedding(d_model&#x3D;d_model,
                                        drop_prob&#x3D;drop_prob,
                                        max_len&#x3D;max_len,
                                        vocab_size&#x3D;dec_voc_size,
                                        device&#x3D;device)

        self.layers &#x3D; nn.ModuleList([DecoderLayer(d_model&#x3D;d_model,
                                                  ffn_hidden&#x3D;ffn_hidden,
                                                  n_head&#x3D;n_head,
                                                  drop_prob&#x3D;drop_prob)
                                     for _ in range(n_layers)])

        self.linear &#x3D; nn.Linear(d_model, dec_voc_size)

    def forward(self, trg, enc_src, trg_mask, src_mask):
        trg &#x3D; self.emb(trg)

        for layer in self.layers:
            trg &#x3D; layer(trg, enc_src, trg_mask, src_mask)

        # pass to LM head
        output &#x3D; self.linear(trg)
        return output</code></pre>
<h2 id="maskedmultiheadattention">MaskedMultiHeadAttention</h2>
<p>整体实现和Encoder的一样，但需要带Masked，实际上，在Encoder中，被pad的地方也要被Masked。</p>
<pre class="line-numbers language-none"><code class="language-none">class DecoderLayer(nn.Module):

    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):
        super(DecoderLayer, self).__init__()
        self.self_attention &#x3D; MultiHeadAttention(d_model&#x3D;d_model, n_head&#x3D;n_head)
        self.norm1 &#x3D; LayerNorm(d_model&#x3D;d_model)
        self.dropout1 &#x3D; nn.Dropout(p&#x3D;drop_prob)

        self.enc_dec_attention &#x3D; MultiHeadAttention(d_model&#x3D;d_model, n_head&#x3D;n_head)
        self.norm2 &#x3D; LayerNorm(d_model&#x3D;d_model)
        self.dropout2 &#x3D; nn.Dropout(p&#x3D;drop_prob)

        self.ffn &#x3D; PositionwiseFeedForward(d_model&#x3D;d_model, hidden&#x3D;ffn_hidden, drop_prob&#x3D;drop_prob)
        self.norm3 &#x3D; LayerNorm(d_model&#x3D;d_model)
        self.dropout3 &#x3D; nn.Dropout(p&#x3D;drop_prob)
</code></pre>
<p>Decoder的mask部分相对来说比较复杂。首先需要把被padding的部分先mask上，然后生成一个下三角矩阵。</p>
<p>这里的QKV都来自于上一步，训练中则都是目标。</p>
<h2 id="multiheadattention-1">MultiHeadAttention</h2>
<p>这里和Encoder唯一的区别就是Q来自Decoder中output的emb经过一个Masked注意力来的，其余KV都是从encoder进来的，</p>
<p>这是因为Decoder
需要关注源序列的信息，以便对当前位置进行合适的预测。这种信息主要来自于
Encoder 的输出，因为 Encoder
能够将源序列的信息编码为一个上下文向量序列，Decoder
通过关注这些上下文向量，能够获取源序列的语义信息。Decoder
还需要考虑已经生成的部分目标序列，以便保持生成的连贯性和合理性。这种信息主要来自于
Decoder 自身的前面层输出，因为 Decoder
在每个时间步都会生成一个新的目标序列标记，这些标记构成了一个逐步生成的序列。</p>
<h2 id="position-wise-feed-forward-networks-1">Position-wise
Feed-Forward Networks</h2>
<p>同Encoder</p>
<h2 id="linear">Linear</h2>
<pre class="line-numbers language-none"><code class="language-none">self.linear &#x3D; nn.Linear(d_model, dec_voc_size)</code></pre>
<h2 id="softmax">softmax</h2>
<p>训练时不需要，推理时才需要</p>
</div></section><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>iroha</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://example.com/post/transformer.html" title="transformer结构与代码">http://example.com/post/transformer.html</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><span class="icon iconify" data-icon="ri:creative-commons-line"></span><span class="icon iconify" data-icon="ri:creative-commons-by-line"></span><span class="icon iconify" data-icon="ri:creative-commons-nc-line"></span><span class="icon iconify" data-icon="ri:creative-commons-sa-line"></span></a> 许可协议。</li></ul></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/post/T5.html" rel="prev" title="T5及相关解析"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">T5及相关解析</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/post/PE.html" rel="next" title="Position Encoding"><span class="post-nav-text">Position Encoding</span><span class="icon iconify" data-icon="ri:arrow-right-s-line"></span></a></div></div></div><div class="hty-card" id="comment"></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2024 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> iroha</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v6.3.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.9</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></body></html>